{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "645ef832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from evaluator_Linear import evaluator\n",
    "from probLearner import PMLearner, RewardLearner, PALearner\n",
    "from ratioLearner import  RatioLinearLearner as RatioLearner\n",
    "from qLearner_Linear import Qlearner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff8aa1",
   "metadata": {},
   "source": [
    "## STEP0: prepare the dataset\n",
    "\n",
    "The following is an example of a proper input dataset with 2 trajectories and 3 observations for each trajectory, which is a dictionary with keys:\n",
    "- s0: stacked initial states of all the trajectories, initial state, 2d-array\n",
    "- state: stacked states of all the trajectories at all time points, 2d-array\n",
    "- action: stacked sequence of actions for all trajectories at all time points, 1d-array\n",
    "- mediator: stacked mediators of all the trajectories at all time points, 2d-array\n",
    "- reward: stacked sequence of rewards for all trajectories at all time points, 1d-array\n",
    "- next_state: stacked next_states of all the trajectories at all time points, 2d-array\n",
    "- **time_idx: stacked time step index, 1d-array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08298ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Simulator import Simulator\n",
    "#dim_state=3; dim_mediator = 2\n",
    "#simulator = Simulator(model_type='Gaussian_semi', dim_state=dim_state, dim_mediator = dim_mediator)\n",
    "#simulator.sample_trajectory(num_trajectory=30, num_time=30, seed=0)\n",
    "#simulator.trajectory2iid()\n",
    "#sim_iid_dataset = simulator.iid_dataset\n",
    "#dataset = sim_iid_dataset\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480cef3",
   "metadata": {},
   "source": [
    "## STEP1ï¼š Learn the behavior policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab333a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qbehavior import Learn_Behavior_Q\n",
    "dim_state=1; dim_mediator = 2; seed=10\n",
    "problearner_parameters = {\"splitter\":[\"best\",\"random\"], \"max_depth\" : range(1,20)},\n",
    "Q_settings = {'scaler': 'Identity','product_tensor': False, 'beta': 3/7, 'include_intercept': False,\n",
    "                               'expectation_MCMC_iter_Q3': 100, 'expectation_MCMC_iter_Q_diff':100, 'penalty': 10**(-4),\n",
    "                              'd': 3, 'min_L': 7}\n",
    "Q_est = Learn_Behavior_Q(dataset, PMLearner, PALearner, dim_state, dim_mediator, problearner_parameters, Q_settings, seed)\n",
    "import pickle\n",
    "with open(\"Q_behavior_S_mood.pickle\",\"wb\") as fp:\n",
    "    pickle.dump(Q_est, fp, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
